{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0feff179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "517201aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_split_pat = re.compile(r\"\\W+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe881171",
   "metadata": {},
   "outputs": [],
   "source": [
    "text: str\n",
    "with open(\"./corpora/sherlock.txt\", \"r\") as f:\n",
    "    text = f.read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eccf18d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'a', 'study', 'in', 'scarlet', 'arthur', 'conan', 'doyle', 'table', 'of']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_words(s: str) -> list[str]:\n",
    "    return re.split(word_split_pat, s)\n",
    "\n",
    "\n",
    "words = split_words(text)\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f194f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a'],\n",
       " ['s', 't', 'u', 'd', 'y'],\n",
       " ['i', 'n'],\n",
       " ['s', 'c', 'a', 'r', 'l', 'e', 't'],\n",
       " ['a', 'r', 't', 'h', 'u', 'r'],\n",
       " ['c', 'o', 'n', 'a', 'n'],\n",
       " ['d', 'o', 'y', 'l', 'e'],\n",
       " ['t', 'a', 'b', 'l', 'e'],\n",
       " ['o', 'f'],\n",
       " ['c', 'o', 'n', 't', 'e', 'n', 't', 's']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_chars(words: list[str]) -> list[list[str]]:\n",
    "    return list(filter(lambda xs: len(xs) > 0, [[c for c in w] for w in words]))\n",
    "\n",
    "\n",
    "chars = split_chars(words)\n",
    "chars[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "988c9af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce(tokens: list[list[str]]) -> tuple[str, list[list[str]]]:\n",
    "    cache: dict[str, int] = {}\n",
    "\n",
    "    for word in tokens:\n",
    "        for fst, scnd in zip(word, word[1:]):\n",
    "            pair = fst + \" \" + scnd\n",
    "            if pair in cache.keys():\n",
    "                continue\n",
    "            pair_pat = re.compile(fst + scnd)\n",
    "            freq = 0\n",
    "            for wordlist in tokens:\n",
    "                word = \"\".join(wordlist)\n",
    "                freq += len(re.findall(pair_pat, word))\n",
    "\n",
    "            cache[pair] = freq\n",
    "\n",
    "    space_seperated_replacement_token, _ = max(\n",
    "        cache.items(), key=lambda x: x[1]\n",
    "    )  # still contains a whitespace\n",
    "    fst, scnd = space_seperated_replacement_token.split()\n",
    "    replacement_token = space_seperated_replacement_token.replace(\" \", \"\")\n",
    "\n",
    "    new_tokens = []\n",
    "\n",
    "    for w in tokens:\n",
    "        if fst in w and scnd in w:\n",
    "            if w.index(fst) == w.index(scnd) - 1:\n",
    "                new_word = (\n",
    "                    w[: w.index(fst)] + [replacement_token] + w[w.index(scnd) + 1 :]\n",
    "                )\n",
    "                new_tokens.append(new_word)\n",
    "                continue\n",
    "        new_tokens.append(w)\n",
    "\n",
    "    return replacement_token, new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7efb1c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpe(text: str, nsteps: int) -> tuple[set[str], list[list[str]]]:\n",
    "    vocab = set()\n",
    "    words = split_words(text)\n",
    "    tokens = split_chars(words)\n",
    "\n",
    "    for w in tokens:\n",
    "        for c in w:\n",
    "            vocab.add(c)\n",
    "\n",
    "    for _ in range(nsteps):\n",
    "        new_token, tokens = reduce(tokens)\n",
    "        vocab.add(new_token)\n",
    "\n",
    "    return vocab, tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9235b89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, tokens = bpe(text, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b3657cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['th',\n",
       " 'q',\n",
       " '6',\n",
       " 'u',\n",
       " 'c',\n",
       " 'l',\n",
       " 'o',\n",
       " 'g',\n",
       " 's',\n",
       " '9',\n",
       " '0',\n",
       " 't',\n",
       " 'h',\n",
       " '7',\n",
       " '2',\n",
       " 'v',\n",
       " '3',\n",
       " 'x',\n",
       " 'n',\n",
       " 'r',\n",
       " 'e',\n",
       " '8',\n",
       " 'y',\n",
       " 'b',\n",
       " 'j',\n",
       " 'd',\n",
       " 'i',\n",
       " 'Ã£',\n",
       " 'k',\n",
       " '4',\n",
       " '5',\n",
       " 'w',\n",
       " 'p',\n",
       " 'z',\n",
       " 'f',\n",
       " 'a',\n",
       " '1',\n",
       " 'm']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([t for t in vocab], key=lambda s: len(s), reverse=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
